Sauvegarde et restauration de mongodb gros volumes
##################################################


Préconisation
===============

Il est fortement conseillé de faire une sauvegarde (`backup`) avant toute migration (montée de version :term:`VITAM`)


Sauvegarde MongoC et MongoD
===========================

Information sur la sauvegarde
-----------------------------

La documentation officielle de MongoDB parle déjà de différentes techniques de Sauvegarde:
    - Sauvegarde en utilisant mongodump (Cf. la :doc:`section dédiée <16-backup_restore>`))
    - Sauvegarde en utilisant Filesystem snapshots
    - Sauvegarde par copie de disque.


.. seealso::

    Pour plus d'information, veuillez-vous référer à la documentation officielle :
    `Monog dump <https://docs.mongodb.com/manual/tutorial/backup-and-restore-tools/>`_ et `Filesystem Snapshots <https://docs.mongodb.com/manual/tutorial/backup-with-filesystem-snapshots/>`_.

La technique choisie par :term:`VITAM` est celle de copie de disque pour plusieurs raisons:

    - La taille de chaque shard est suffisamment grande. L'outil mongodump n'est pas conseillé dans ce cas de figure.
    - La restauration prendra beaucoup de temps (restauration des données + création d'indexes)
    - L'usage de mongodump impacte les performances


Procédure de sauvegarde
-----------------------

1. Repérer dans le replicaSet des instances mongo master (mongoc pour la conf ou mongod pour les shards)
2. Arrêter proprement mongo
3. Copie + zip du dossier db (avec le nommage qui permet d'identifier l'instance mongo) de chaque mongo master précédemment identifié
4. Stocker les zip dans un disque séparé et sécurisé


Restaurer MongoC et MongoD
===========================

Comme la sauvegarde, la documentation officielle parle aussi de la restauration d'un cluster shard mongo.
Pour plus de détails, veuillez cliquer sur ce lien: `Restore sharded cluster <https://docs.mongodb.com/manual/tutorial/restore-sharded-cluster/>`_.

Procédure de restauration
--------------------------

1- Déployer :term:`VITAM` qui va créer un cluster mongo vide,

2- Arrêter le cluster mongo,

3.1- Modifier la configuration de mongod et mongoc pour désactiver la replication et le sharding comme décrit dans la documentation officielle,

3.2- Si vos instances mongo sont dans une zone réseau privée et sécurisée, vous pouvez aussi désactiver l'authentification en commentant la partie sécurité dans le fichier de conf

4- Copier et décompresser vers le dossier db de chaque instance mongo un fichier backup correspondant

  Pour tous les mongoc, c'est le fichier zip backup mongoc qu'il faut mettre,
  Pour chaque shard, il faut mettre le fichier zip du backup correspondant (pour chaque instance du replicaset du shard en question)
  Le nom du zip doit mentionner l'instance mongo sur laquelle, on peut le restaurer

5- Démarrer toutes les instances mongo (en appliquant la modification des fichiers de configuration) une fois avoir copié et décompressé tous les backup sur toutes les instances

6- Dans chacune des instances

 6.1- Si l'authentification est activée, il faut créer un ``systemUser`` (pré-requis: il faut un utilisateur ayant un role "root")

         .. code:: javascript

            use admin
            // Authenticate as root user
            db.auth("rootUser", "rootUserPassword")
            // Create system user
            db.createUser({user: "systmUser", pwd: "systemUserPassword", roles: [ "__system" ]})
            // Authenticate as system user
            db.auth("systmUser", "systemUserPassword")

   6.2- Supprimer la base de données ``local``

         .. code:: javascript

            // Drop local database
            use local
            db.dropDatabase()


   6.3- Pour les instances mongoc: Mettre à jour la collection ``shards``

        .. code:: javascript

            use config
            // spécifier les shards pour chaque mongoc
            // Example
            db.shards.updateOne({ "_id" : "shard01"},  { $set : { "host" : "shard01/shard01a:28018,shard01b:28018"}})
            db.shards.updateOne({ "_id" : "shard02"},  { $set : { "host" : "shard02/shard02a:28019,shard02b:28019"}})
            db.shards.updateOne({ "_id" : "shard03"},  { $set : { "host" : "shard03/shard03a:28020,shard03b:28020"}})


   6.4- Pour les instances mongod (les shards): Mettre à jour la collection ``system.version``

        .. code:: javascript

            use admin
            db.system.version.deleteOne( { "_id": "minOpTimeRecovery" } )
            // spécifier les mongoc pour chaque shard
            // Example
             db.system.version.updateOne({ "_id" : "shardIdentity" },{ $set :{ "configsvrConnectionString" : "configserver/config01:28017,config02:28017,config03:28017"}})


   6.5- Si vous avez crée un utilisateur ayant un role ``__system`` à l'étape (6.1), il faut donc le supprimer

        .. code:: javascript

            // Remove system user
            use admin
            // Authenticate as root user
            db.auth("rootUser", "rootUserPassword")
            db.removeUser("systmeUser")

7- Arrêter mongodb et réactiver la replication et le sharding (et l'authentification si désactivée) dans la conf de chacune des instances

8- Démarrer Mongo

9- Activer les ``replicaSet`` pour chacun des mongoc et mongod (shards)


.. code:: bash

    // Sur un des mongoc
    > mongo --host {{ ip_service }} --port {{ mongodb.mongoc_port }} {{ vitam_defaults.folder.root_path }}/app/mongoc/init-replica-config.js
    // Pour chaque shards et sur un des shards d'un replicaset
    > mongo --host {{ ip_service }} --port {{ mongodb.mongod_port }} {{ vitam_defaults.folder.root_path }}/app/mongod/init-replica-config.js

10- Test de la restauration

    - Un document accessible depuis un shards devrait être accessible depuis ``mongos`` (faire la requête de test sur chaque shard)
    - Tester aussi les collections non shardées
    - Il est conseillé de faire un ``count`` sur chacune des collections avant la sauvegarde pour vérifier lors de la restauration qu'on a bien les bons ``count``.


.. note::

    Si l'adresse ip et numéro de port de chacune des instances mongo du cluster recrée ne sont pas changés, alors les étapes 1, 2, 4, 8 et 10 sont suffisantes et le cluster mongo devrait fonctionner sans problème.

    Dans le cas ou la sécurité reste activée vous devez créer un utilisateur ayant un role "``__system``" et s'authentifier avec cet utilisateur pour pouvoir faire les modifications :

    .. caution:: Le pré-requis dans ce cas est d'avoir un utilisateur ayant un role "``root``" pour pouvoir créer un utilisateur ayant un rôle "``__system``"

L'ansiblerie :term:`VITAM` déploie dans chacune des instances mongoc et mongod des scripts préparés restaure-mongoc.js et restaure-mongod.js respectivement

        - {{ vitam_defaults.folder.root_path }}/app/mongoc/restaure-mongoc.js
        - {{ vitam_defaults.folder.root_path }}/app/mongod/restaure-mongod.js

Toutes les informations sur les adresses ip et numéros de ports de toutes les instances du cluster mongo sont automatiquement renseignés dans ces scripts

Pour exécuter ces deux scripts, il faut lancer la commande suivante que vous pouvez automatiser dans un playbook:

.. code:: bash

        // Sur mongoc
       > mongo {{ ip_service }}:{{ mongodb.mongos_port }}/admin {{ mongo_credentials }} {{ vitam_defaults.folder.root_path }}/app/mongoc/restaure-mongoc.js
        // Sur mongod
       > mongo {{ ip_service }}:{{ mongodb.mongos_port }}/admin {{ mongo_credentials }} {{ vitam_defaults.folder.root_path }}/app/mongod/restaure-mongod.js


Sauvegarde et restauration de l'offre froide
============================================
En plus de la procédure de backup et restauration décrite ci-dessus, pour :term:`VITAM` ayant une offre de stockage froide, les fichiers backup zip sont stockés dans des bandes magnétiques.

Sauvegarde
----------
La procédure de backup du mongo de l'offre froide est très importante, car, mongo joue le rôle d'un référentiel de tout ce qui est dans les bandes magnétiques.

En gros, si on perd mongo de l'offre froide, toutes les informations enregistrées sur les bandes magnétiques sont inutilisables.

C'est pour cette raison, que nous faisons, impérativement, au préalable:

    - La sauvegarde du mongo de l'offre froide
    - La sauvegarde est stockée sur bande magnétique.


Sauvegarde côté cluster mongo de l'offre froide
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Un playbook, ayant les tâches ci-dessous, a été mis en place pour faire un backup du mongo de l'offre froide:

    1. Détection des Mongo ``master``
    2. Arrêt de :term:`VITAM`
    3. Copie + ajout d'un fichier ayant des informations sur l'instance en cours  + compression du dossier db de chaque instance ``master``
    4. Démarrer :term:`VITAM`
    5. Envoi des fichiers zip via CURL vers l'offre froide qui seront sauvegardés sur une bande magnétique


Pour exécuter le playbook :

.. caution:: Le playbook ci-dessous est à exécuter uniquement sur un :term:`VITAM` ayant une offre froide ``**tapeLibrary**``

.. code:: bash

	ansible-playbook -i environments/hosts.deployment ansible-vitam-exploitation/backup_mongodb_tape_offer.yml --ask-vault-pass --tags update_vitam_configuration


Sauvegarde côté offre froide
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lors de l'envoi de fichier via un CURL vers l'offre froide, cette dernière va procéder comme suit:

- Réception du fichier zip dans une zone temporaire
- Copie du fichier dans une zone d'écriture sur bande magnétique
- Création d'un ordre spécifique pour écrire le fichier backup zip sur une bande magnétique ayant un tag ``backup``
- Le worker qui va exécuter la tâche ayant l'ordre spécifique va écrire dans un fichier log ``offer_tape_backup_DATE.log`` les informations : ``code de la bande magnétique``, ``mongoc`` ou ``mongod (shard(i)``, ``date``.

.. note::
    Lors de la lecture depuis une bande magnétique, on aura un fichier zip mais sans connaitre son nom et son type.
    Si on perd tout mongo, uniquement ce fichier log ``offer_tape_backup_DATE.log`` pourra nous renseigner sur le nom du fichier et sur le code de la bande magnétique ou a été écrit le fichier de backup.
    Le nom ``DATE-disk-mongod-shard01_.zip`` qu'on récupère depuis le fichier log ``offer_tape_backup_DATE.log`` nous renseigne sur la date et le fait que ce soit un backup du ``shard01``. Il ne peut donc être restauré que dans un ``mongod`` et non pas ``mongoc``



Restauration
------------

Restaurer côté offre froide
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sur l'offre froide, toutes les écritures de fichiers zip dans le cas de backup de mongodb de l'offre, sont tracées dans un fichier log ``offer_tape_backup_DATE.log``

On peut facilement repérer des lignes de log ayant comme information:

    - Le code de la bande magnétique sur laquelle est écrit le fichier
    - Le nom du fichier de la forme ``DATE-disk-mongod-shard01_.zip``

On saura donc dans quelle bande magnétique lire le fichier en question.

.. warning::
    Il est fortement conseillé de copier ce fichier log ``offer_tape_backup_DATE.log`` dans un lieu sûr pour le besoin de restauration en cas de perte du site.
    Dans le cas contraire, on doit lire toutes les bandes magnétiques pour espérer retrouver les fichiers backup.

Pour restaurer une date donnée ::

 - On doit repérer dans le fichier log ``offer_tape_backup_DATE.log`` tous les fichiers backup ``(mongoc et mongod)`` zip correspondant à cette date ainsi que les bandes magnétiques sur lequelles on peut les lire
 - Manuellement charger les bandes magnétiques sur une ``tape-library`` pour lire les fichiers en question
 - Renommer chacun des fichiers avec le nom adéquat (le nom se retrouve aussi à l'intérieur du fichier zip dans un fichier descriptif)
 - Copier et décompresser chacun de ces fichiers dans l'instance mongo correspondante : Un fichier ayant un nom ``DATE-disk-mongod-shard01_.zip`` est à copier et à décompresser dans toutes les instances mongo du shard ``shard01``

Restaurer côté cluster mongo de l'offre froide
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Une fois tous les fichiers copiés et décompressés dans les instances mongo correspondantes, il faut suivre la procédure de restauration décrite ci-dessus paragraphe **Restaurer MongoC et MongoD**.

Cas de la base mongo certificates
==================================

Se référer à :ref:`backupidentity`
