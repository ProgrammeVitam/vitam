---
### global ###

# Disable epel or Debian backports repositories install
disable_internet_repositories_install: false

# TODO MAYBE : permettre la surcharge avec une syntax du genre vitamopts.folder_root | default(vitam_default.folder_root) dans les templates ?
droid_filename: "DROID_SignatureFile_V97.xml"
droid_container_filename: "container-signature-20201001.xml"

# The global defaults parameters for vitam & vitam components
vitam_defaults:
    folder:
        root_path: /vitam
        folder_permission: "0750"
        conf_permission: "0640"
        folder_upload_permission: "0770"
        script_permission: "0750"
    users:
        vitam: "vitam"
        vitamdb: "vitamdb"
        group: "vitam"
    services:
        # Default log level for vitam components: logback values (TRACE, DEBUG, INFO, WARN, ERROR, OFF)
        log_level: WARN
        start_timeout: 300
        stop_timeout: 3600
        port_service_timeout: 86400
        api_call_timeout: 120
        api_long_call_timeout: 300
        status_retries_number: 60
        status_retries_delay: 5
### Trust X-SSL-CLIENT-CERT header for external api auth ? (true | false)
    vitam_ssl_user_header: true
### Force chunk mode : set true if chunk header should be checked
    vitam_force_chunk_mode: false
    # syslog_facility
    syslog_facility: local0

################################################################################
### Default Components parameters
### Uncomment them if you want to update the default value applied on all components

### Ontology cache settings (max entries in cache & retention timeout in seconds)
    # ontologyCacheMaxEntries: 100
    # ontologyCacheTimeoutInSeconds: 300
### Elasticsearch scroll timeout in milliseconds settings
    # elasticSearchScrollTimeoutInMilliseconds: 300000

### The following values can be overwritten for each components in vitam: parameters.
    jvm_log: false
    performance_logger: false

    # consul_business_check: 10 # value in seconds
    # consul_admin_check: 10 # value in seconds

    # metricslevel: DEBUG
    # metricsinterval: 3
    # metricsunit: MINUTES

    # access_retention_days: 30 # Number of days for file retention
    # access_total_size_cap: "10GB" # total acceptable size
    # logback_max_file_size: "10MB"
    # logback_total_size_cap:
    #   file:
    #     history_days: 30
    #     totalsize: "5GB"
    #   security:
    #     history_days: 30
    #     totalsize: "5GB"

### Logs configuration for reconstruction services (INFO or DEBUG for active logs).
### Logs will be present only on secondary site.
### Available for the following components: logbook, metadata & functional-administration.
    reconstruction:
        log_level: INFO

# Used in ingest, unitary update, mass-update
classificationList: ["Non protégé","Secret Défense", "Confidentiel Défense"]
# Used in ingest, unitary update, mass-update
classificationLevelOptional: true
# Packages install retries
packages_install_retries_number: 1
packages_install_retries_delay: 10

# Request time check settings. Do NOT update except if required by Vitam support
# Max acceptable time desynchronization between machines (in seconds).
acceptableRequestTime: 10
# Critical time desynchronization between machines (in seconds).
criticalRequestTime: 60
# Request time alert throttling Delay (in seconds)
requestTimeAlertThrottlingDelay: 60

vitam_timers:
# /!\ IMPORTANT :
# Please ensure timer execution is spread so that not all timers run concurrently (eg. *:05:00, *:35:00, *:50:00..),
# Special care for heavy-load timers that run on same machines or use same resources (eg. vitam-traceability-*).
#
# systemd nomenclature
#    minutely → *-*-* *:*:00
#    hourly → *-*-* *:00:00
#    daily → *-*-* 00:00:00
#    monthly → *-*-01 00:00:00
#    weekly → Mon *-*-* 00:00:00
#    yearly → *-01-01 00:00:00
#    quarterly → *-01,04,07,10-01 00:00:00
#    semiannually → *-01,07-01 00:00:00
    logbook: # all have to run on only one machine
        # Sécurisation des journaux des opérations
        - name: vitam-traceability-operations
          frequency: "*-*-* *:05:00" # every hour
        # Sécurisation des journaux du cycle de vie des groupes d'objets
        - name: vitam-traceability-lfc-objectgroup
          frequency: "*-*-* *:15:00" # every hour
        # Sécurisation des journaux du cycle de vie des unités archivistiques
        - name: vitam-traceability-lfc-unit
          frequency: "*-*-* *:35:00" # every hour
        # Audit de traçabilité
        - name: vitam-traceability-audit
          frequency: "*-*-* 00:55:00"
        # Reconstruction (uniquement sur site secondaire)
        - name: vitam-logbook-reconstruction
          frequency: "*-*-* *:0/5:00"
    storage:
        # Sauvegarde des journaux d'accès
        - name: vitam-storage-accesslog-backup
          frequency: "*-*-* 0/4:10:00" # every 4 hours
        # Sauvegarde des journaux des écritures
        - name: vitam-storage-log-backup
          frequency: "*-*-* 0/4:15:00" # every 4 hours
        # Sécurisation du journal des écritures
        - name: vitam-storage-log-traceability
          frequency: "*-*-* 0/4:40:00" # every 4 hours
    functional_administration:
        - name: vitam-create-accession-register-symbolic
          frequency: "*-*-* 00:50:00"
        - name: vitam-functional-administration-accession-register-reconstruction
          frequency: "*-*-* *:0/5:00"
        - name: vitam-rule-management-audit
          frequency: "*-*-* *:40:00"
        - name: vitam-functional-administration-reconstruction
          frequency: "*-*-* *:0/5:00"
    metadata:
        - name: vitam-metadata-store-graph
          frequency: "*-*-* *:10/30:00"
        - name: vitam-metadata-reconstruction
          frequency: "*-*-* *:0/5:00"
        - name: vitam-metadata-computed-inherited-rules
          frequency: "*-*-* 02:30:00"
        - name: vitam-metadata-purge-dip
          frequency: "*-*-* 02:20:00"
        - name: vitam-metadata-purge-transfers-SIP
          frequency: "*-*-* 02:25:00"
        - name: vitam-metadata-audit-mongodb-es
          frequency: "2020-01-01 00:00:00"
    offer:
      # Compaction offer logs
      - name: vitam-offer-log-compaction
        frequency: "*-*-* *:40:00" # every hour

### consul ###
# WARNING: consul_domain should be a supported domain name for your organization
#          You will have to generate server certificates with the same domain name and the service subdomain name
#          Example: consul_domain=vitam means you will have to generate some certificates with .service.vitam domain
#                   access-external.service.vitam, ingest-external.service.vitam, ...
consul_domain: consul
consul_folder_conf: "{{ vitam_defaults.folder.root_path }}/conf/consul"

# Workspace should be useless but storage have a dependency to it...
# elastic-kibana-interceptor is present as kibana is present, if kibana-data & interceptor are not needed in the secondary site, just do not add them in the hosts file
vitam_secondary_site_components: [ "logbook" , "metadata" , "functional-administration" , "storage" , "storageofferdefault" , "offer" , "elasticsearch-log" , "elasticsearch-data" , "logstash" , "kibana" , "mongoc" , "mongod" , "mongos", "elastic-kibana-interceptor" , "consul" ]

# containers list
containers_list: ['units', 'objects', 'objectgroups', 'logbooks', 'reports', 'manifests', 'profiles', 'storagelog', 'storageaccesslog', 'storagetraceability', 'rules', 'dip', 'agencies', 'backup', 'backupoperations', 'unitgraph', 'objectgroupgraph', 'distributionreports', 'accessionregistersdetail', 'accessionregisterssymbolic', 'tmp', 'archivaltransferreply']

# Vitams griffins required to launch preservation scenario
# Example:
# vitam_griffins: ["vitam-imagemagick-griffin", "vitam-libreoffice-griffin", "vitam-jhove-griffin", "vitam-odfvalidator-griffin", "vitam-siegfried-griffin", "vitam-tesseract-griffin", "vitam-verapdf-griffin", "vitam-ffmpeg-griffin"]
vitam_griffins: []

### Composants Vitam ###
vitam:
### All available parameters for each components are described in the vitam_defaults variable

### Example
  # component:
  #    logback_rolling_policy: true
  ## Force the log level for this component. Available logback values are (TRACE, DEBUG, INFO, WARN, ERROR, OFF)
  ## If this var is not set, the default one will be used (vitam_defaults.services.log_level)
  #    log_level: "DEBUG"

    accessexternal:
        # Component name: do not modify
        vitam_component: access-external
        # DNS record for the service:
        # Modify if ihm-demo is not using consul (typical production deployment)
        host: "access-external.service.{{ consul_domain }}"
        port_admin: 28102
        port_service: 8444
        baseuri: "access-external"
        https_enabled: true
        # Use platform secret for this component ? : do not modify
        secret_platform: "false"
    accessinternal:
        vitam_component: access-internal
        host: "access-internal.service.{{ consul_domain }}"
        port_service: 8101
        port_admin: 28101
        baseuri: "access-internal"
        https_enabled: false
        secret_platform: "true"
    functional_administration:
        vitam_component: functional-administration
        host: "functional-administration.service.{{ consul_domain }}"
        port_service: 8004
        port_admin: 18004
        baseuri: "adminmanagement"
        https_enabled: false
        secret_platform: "true"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # Number of AccessionRegisterSymbolic creation threads that can be run in parallel.
        accessionRegisterSymbolicThreadPoolSize: 16
        # Number of rule audit threads that can be run in parallel.
        ruleAuditThreadPoolSize: 16
    elastickibanainterceptor:
        vitam_component: elastic-kibana-interceptor
        host: "elastic-kibana-interceptor.service.{{ consul_domain }}"
        port_service: 8014
        port_admin: 18014
        baseuri: ""
        https_enabled: false
        secret_platform: "false"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
    batchreport:
        vitam_component: batch-report
        host: "batch-report.service.{{ consul_domain }}"
        port_service: 8015
        port_admin: 18015
        baseuri: "batchreport"
        https_enabled: false
        secret_platform: "false"
    ingestexternal:
        vitam_component: ingest-external
        # DNS record for the service:
        # Modify if ihm-demo is not using consul (typical production deployment)
        host: "ingest-external.service.{{ consul_domain }}"
        port_admin: 28001
        port_service: 8443
        baseuri: "ingest-external"
        https_enabled: true
        secret_platform: "false"
        antivirus: "clamav" # or avast
        #scantimeout: 1200000 # value in milliseconds; increase this value if huge files need to be analyzed in more than 20 min (default value)
        # Directory where files should be placed for local ingest
        upload_dir: "/vitam/data/ingest-external/upload"
        # Directory where successful ingested files will be moved to
        success_dir: "/vitam/data/ingest-external/upload/success"
        # Directory where failed ingested files will be moved to
        fail_dir: "/vitam/data/ingest-external/upload/failure"
        # Action done to file after local ingest (see below for further information)
        upload_final_action: "MOVE"
        # upload_final_action can be set to three different values (lower or upper case does not matter)
        #   MOVE : After upload, the local file will be moved to either success_dir or fail_dir depending on the status of the ingest towards ingest-internal
        #   DELETE : After upload, the local file will be deleted if the upload succeeded
        #   NONE : After upload, nothing will be done to the local file (default option set if the value entered for upload_final_action does not exist)
    ingestinternal:
        vitam_component: ingest-internal
        host: "ingest-internal.service.{{ consul_domain }}"
        port_service: 8100
        port_admin: 28100
        baseuri: "ingest"
        https_enabled: false
        secret_platform: "true"
    ihm_demo:
        vitam_component: ihm-demo
        host: "ihm-demo.service.{{ consul_domain }}"
        port_service: 8446
        port_admin: 28002
        baseurl: "/ihm-demo"
        static_content: "{{ vitam_defaults.folder.root_path }}/app/ihm-demo/v2"
        baseuri: "ihm-demo"
        https_enabled: true
        # metrics_enabled: false # Set to false if ihm_demo component is outside the Vitam area (default: true)
        secret_platform: "false"
        # User session timeout in milliseconds (for shiro)
        session_timeout: 1800000
        secure_cookie: true
        # Specify here the realms you want to use for authentication in ihm-demo
        # You can set multiple realms, one per line
        # With multiple realms, the user will be able to choose between the allowed realms
        # Example: authentication_realms:
        #               - x509Realm
        #               - ldapRealm
        # Authorized values:
        # x509Realm: certificate
        # iniRealm: ini file
        # ldapRealm: ldap
        authentication_realms:
            # - x509Realm
            - iniRealm
            # - ldapRealm
        allowedMediaTypes:
            - type: "application"
              subtype: "pdf"
            - type: "text"
              subtype: "plain"
            - type: "image"
              subtype: "jpeg"
            - type: "image"
              subtype: "tiff"
    logbook:
        vitam_component: logbook
        host: "logbook.service.{{ consul_domain }}"
        port_service: 9002
        port_admin: 29002
        baseuri: "logbook"
        https_enabled: false
        secret_platform: "true"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # Temporization delay (in seconds) for recent logbook operation events.
        # Set it to a reasonable delay to cover max clock difference across servers + VM/GC pauses
        operationTraceabilityTemporizationDelay: 300
        # Max delay between 2 logbook operation traceability operations.
        # A new logbook operation traceability is generated after this delay, even if tenant has no
        # new logbook operations to secure
        # Unit can be in DAYS, HOURS, MINUTES, SECONDS
        # Hint: Set it to 690 MINUTES (11 hours and 30 minutes) to force new traceability after +/- 12 hours (supposing
        # logbook operation traceability timer run every hour +/- some clock delays)
        operationTraceabilityMaxRenewalDelay: 690
        operationTraceabilityMaxRenewalDelayUnit: MINUTES
        # Number of logbook operations that can be run in parallel.
        operationTraceabilityThreadPoolSize: 16
        # Temporization delay (in seconds) for recent logbook lifecycle events.
        # Set it to a reasonable delay to cover max clock difference across servers + VM/GC pauses
        lifecycleTraceabilityTemporizationDelay: 300
        # Max delay between 2 lifecycle traceability operations.
        # A new unit/objectgroup lifecycle traceability is generated after this delay, even if tenant has no
        # new unit/objectgroups to secure
        # Unit can be in DAYS, HOURS, MINUTES, SECONDS
        # Hint: Set it to 690 MINUTES (11 hours and 30 minutes) to force new traceability after +/- 12 hours (supposing
        # LFC traceability timers run every hour +/- some clock delays)
        lifecycleTraceabilityMaxRenewalDelay: 690
        lifecycleTraceabilityMaxRenewalDelayUnit: MINUTES
        # Max entries selected per (Unit or Object Group) LFC traceability operation
        lifecycleTraceabilityMaxEntries: 100000
    metadata:
        vitam_component: metadata
        host: "metadata.service.{{ consul_domain }}"
        port_service: 8200
        port_admin: 28200
        baseuri: "metadata"
        https_enabled: false
        secret_platform: "true"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # Archive Unit Profile cache settings (max entries in cache & retention timeout in seconds)
        archiveUnitProfileCacheMaxEntries: 100
        archiveUnitProfileCacheTimeoutInSeconds: 300
        # Schema validator cache settings (max entries in cache & retention timeout in seconds)
        schemaValidatorCacheMaxEntries: 100
        schemaValidatorCacheTimeoutInSeconds: 300
        # DIP cleanup delay (in minutes)
        dipTimeToLiveInMinutes: 10080 # 7 days
        transfersSIPTimeToLiveInMinutes: 10080 # 7 days
        elasticsearch_mapping_dir: "{{ vitam_defaults.folder.root_path }}/conf/metadata/mapping" # Directory of elasticsearch metadata mapping
        #### Audit data consistency MongoDB-ES ####
        isDataConsistencyAuditRunnable: false
        dataConsistencyAuditOplogMaxSize: 100
    processing:
        vitam_component: processing
        host: "processing.service.{{ consul_domain }}"
        port_service: 8203
        port_admin: 28203
        baseuri: "processing"
        https_enabled: false
        secret_platform: "true"
        maxDistributionInMemoryBufferSize: 100000
        maxDistributionOnDiskBufferSize: 100000000
    security_internal:
        vitam_component: security-internal
        host: "security-internal.service.{{ consul_domain }}"
        port_service: 8005
        port_admin: 28005
        baseuri: "security-internal"
        https_enabled: false
        secret_platform: "true"
    storageengine:
        vitam_component: storage
        host: "storage.service.{{ consul_domain }}"
        port_service: 9102
        port_admin: 29102
        baseuri: "storage"
        https_enabled: false
        secret_platform: "true"
        storageTraceabilityOverlapDelay: 300
        restoreBulkSize: 1000
        # Storage write/access log backup max thread pool size
        storageLogBackupThreadPoolSize: 16
        # Storage write log traceability thread pool size
        storageLogTraceabilityThreadPoolSize: 16
        # Offer synchronization batch size & thread pool size
        offerSynchronizationBulkSize: 1000
        # Retries attempts
        offerSyncNumberOfRetries: 3
        offerSyncFirstAttemptWaitingTime: 15
        offerSyncWaitingTime: 30
        offerSyncThreadPoolSize: 32
        logback_total_size_cap:
          offersync:
            history_days: 30
            totalsize: "5GB"
          offerdiff:
            history_days: 30
            totalsize: "5GB"
        # unit time per kB (in ms) used while calculating the timeout of an http request between storage and offer.
        timeoutMsPerKB: 100
        # minimum timeout (in ms) for writing objects to offers
        minWriteTimeoutMs: 60000
        # minimum timeout per object (in ms) for bulk writing objects to offers
        minBulkWriteTimeoutMsPerObject: 10000
    storageofferdefault:
        vitam_component: "offer"
        port_service: 9900
        port_admin: 29900
        baseuri: "offer"
        https_enabled: false
        secret_platform: "true"
        logback_total_size_cap:
          offer_tape:
            history_days: 30
            totalsize: "5GB"
          offer_tape_backup:
            history_days: 30
            totalsize: "5GB"
    worker:
        vitam_component: worker
        host: "worker.service.{{ consul_domain }}"
        port_service: 9104
        port_admin: 29104
        baseuri: "worker"
        https_enabled: false
        secret_platform: "true"
        api_output_index_tenants: [0,1,2,3,4,5,6,7,8,9]
        rules_index_tenants: [0,1,2,3,4,5,6,7,8,9]
        # Archive Unit Profile cache settings (max entries in cache & retention timeout in seconds)
        archiveUnitProfileCacheMaxEntries: 100
        archiveUnitProfileCacheTimeoutInSeconds: 300
        # Schema validator cache settings (max entries in cache & retention timeout in seconds)
        schemaValidatorCacheMaxEntries: 100
        schemaValidatorCacheTimeoutInSeconds: 300
        # Batch size for bulk atomic update
        queriesThreshold: 100000
        # Bulk atomic update batch size
        bulkAtomicUpdateBatchSize: 100
        # Max threads that can be run in concurrently is thread pool for bulk atomic update
        bulkAtomicUpdateThreadPoolSize: 8
        # Number of jobs that can be queued in memory before blocking for bulk atomic update
        bulkAtomicUpdateThreadPoolQueueSize: 16
    workspace:
        vitam_component: workspace
        host: "workspace.service.{{ consul_domain }}"
        port_service: 8201
        port_admin: 28201
        baseuri: "workspace"
        https_enabled: false
        secret_platform: "true"

# for functional-administration, manage master/slave tenant configuration
vitam_tenants_usage_external:
  - name: 0
    identifiers:
        - INGEST_CONTRACT
        - ACCESS_CONTRACT
        - MANAGEMENT_CONTRACT
        - ARCHIVE_UNIT_PROFILE
  - name: 1
    identifiers:
      - INGEST_CONTRACT
      - ACCESS_CONTRACT
      - MANAGEMENT_CONTRACT
      - PROFILE
      - SECURITY_PROFILE
      - CONTEXT

vitam_tenant_rule_duration:
  - name: 2 # applied tenant
    rules:
      - AppraisalRule : "1 year" # rule name : rule value

# If you want to deploy vitam in a single VM, add the vm name in this array
single_vm_hostnames: ['localhost']
