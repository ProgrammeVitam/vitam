---
### global ###

# Disable epel or Debian backports repositories install
disable_internet_repositories_install: false

# TODO MAYBE : permettre la surcharge avec une syntax du genre vitamopts.folder_root | default(vitam_default.folder_root) dans les templates ?
droid_filename: "DROID_SignatureFile_V95.xml"
droid_container_filename: "container-signature-20180920.xml"

vitam_defaults:
    folder:
        root_path: /vitam
        folder_permission: "0750"
        conf_permission: "0640"
        folder_upload_permission: "0770"
        script_permission: "0750"
    users:
        vitam: "vitam"
        vitamdb: "vitamdb"
        group: "vitam"
    services:
        # Default log level for vitam components: logback values (TRACE, DEBUG, INFO, WARN, ERROR, OFF)
        log_level: WARN
        start_timeout: 300
        stop_timeout: 3600
        port_service_timeout: 86400
        api_call_timeout: 120
        status_retries_number: 60
        status_retries_delay: 5
    # Filter for the vitam package version to install
    # FIXME : commented as has to be removed becuase doesn't work under Debain
    #package_version: "*"
    ### Trust X-SSL-CLIENT-CERT header for external api auth ? (true | false) ###
    vitam_ssl_user_header: true
    ### Force chunk mode : set true if chunk header should be checked
    vitam_force_chunk_mode: false
    # syslog_facility
    syslog_facility: local0

# Used in ingest, unitary update, mass-update
classificationList: ["Non protégé","Secret Défense", "Confidentiel Défense"]
# Used in ingest, unitary update, mass-update
classificationLevelOptional: true
# Packages install retries
packages_install_retries_number: 1
packages_install_retries_delay: 10


vitam_timers:
# systemd nomenclature
#    minutely → *-*-* *:*:00
#    hourly → *-*-* *:00:00
#    daily → *-*-* 00:00:00
#    monthly → *-*-01 00:00:00
#    weekly → Mon *-*-* 00:00:00
#    yearly → *-01-01 00:00:00
#    quarterly → *-01,04,07,10-01 00:00:00
#    semiannually → *-01,07-01 00:00:00
    logbook: # all have to run on only one machine
        # Sécurisation des journaux des opérations
        - name: vitam-traceability-operations
          frequency: "*-*-* 0/2:00:00" # each 2 hours
        # Sécurisation des journaux du cycle de vie des groupes d'objets
        - name: vitam-traceability-lfc-objectgroup
          frequency: "*-*-* 0/4:00:00" # each 4 hours
        # Sécurisation des journaux du cycle de vie des unités archivistiques
        - name: vitam-traceability-lfc-unit
          frequency: "*-*-* 0/3:00:00" # each 3 hours
        # Audit de traçabilité
        - name: vitam-traceability-audit
          frequency: "*-*-* 00:00:00"
        # Reconstruction
        - name: vitam-logbook-reconstruction
          frequency: "*-*-* *:0/5:00"
    storage:
        # Sauvegarde des journaux des écritures
        - name: vitam-storage-accesslog-backup
          frequency: "*-*-* 0/4:00:00" # each 4 hours
        # Sécurisation du journal des écritures
        - name: vitam-storage-log-backup
          frequency: "*-*-* 0/2:00:00" # each 2 hours
        # Log traceability
        - name: vitam-storage-log-traceability
          frequency: "*-*-* 0/2:10:00" # each 2 hours (10 minutes)
    functional_administration:
        - name: vitam-create-accession-register-symbolic
          frequency: "*-*-* 00:00:00"
        - name: vitam-functional-administration-accession-register-reconstruction
          frequency: "*-*-* *:0/5:00"
        - name: vitam-rule-management-audit
          frequency: "*-*-* *:00:00"
        - name: vitam-functional-administration-reconstruction
          frequency: "*-*-* *:0/5:00"
    metadata:
        - name: vitam-metadata-store-graph
          frequency: "*-*-* *:0/30:00"
        - name: vitam-metadata-reconstruction
          frequency: "*-*-* *:0/5:00"


### consul ###
# FIXME: Consul à la racine pour le moment à cause de problèmes de récursivité dans le parsing yaml
# WARNING: consul_domain should be a supported domain name for your organization
#          You will have to generate server certificates with the same domain name and the service subdomain name
#          Example: consul_domain=vitam means you will have to generate some certificates with .service.vitam domain
#                   access-external.service.vitam, ingest-external.service.vitam, ...
consul_domain: consul
consul_component: consul
consul_folder_conf: "{{ vitam_defaults.folder.root_path }}/conf/{{ consul_component }}"

# Workspace should be useless but storage have a dependency to it...
# elastic-kibana-interceptor is present as kibana is present, if kibana-data & interceptor are not needed in the secondary site, just do not add them in the hosts file
vitam_secondary_site_components: [ "logbook" , "metadata" , "functional-administration" , "storage" , "storageofferdefault" , "offer" , "elasticsearch-log" , "elasticsearch-data" , "logstash" , "kibana" , "mongoc" , "mongod" , "mongos", "elastic-kibana-interceptor" , "consul" ]

# Vitams griffins required to launch preservation scenario
vitam_griffins: []

### Composants Vitam ###

vitam:
    # Ontology cache settings (max entries in cache & retention timeout in seconds)
    ontologyCacheMaxEntries: 100
    ontologyCacheTimeoutInSeconds: 300
    accessexternal:
        # Component name: do not modify
        vitam_component: access-external
        # DNS record for the service:
        # Modify if ihm-demo is not using consul (typical production deployment)
        host: "access-external.service.{{ consul_domain }}"
        port_admin: 28102
        port_service: 8444
        baseuri: "access-external"
        https_enabled: true
        # Use platform secret for this component ? : do not modify
        secret_platform: "false"
        # Force the log level for this component: this are logback values (TRACE, DEBUG, INFO, WARN, ERROR, OFF)
        # If this var is not set, the default one will be used (vitam_defaults.services.log_level)
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    accessinternal:
        vitam_component: access-internal
        host: "access-internal.service.{{ consul_domain }}"
        port_service: 8101
        port_admin: 28101
        baseuri: "access-internal"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    functional_administration:
        vitam_component: functional-administration
        host: "functional-administration.service.{{ consul_domain }}"
        port_service: 8004
        port_admin: 18004
        baseuri: "adminmanagement"
        https_enabled: false
        secret_platform: "true"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    elastickibanainterceptor:
        vitam_component: elastic-kibana-interceptor
        host: "elastic-kibana-interceptor.service.{{ consul_domain }}"
        port_service: 8014
        port_admin: 18014
        baseuri: ""
        https_enabled: false
        secret_platform: "false"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    batchreport:
        vitam_component: batch-report
        host: "batch-report.service.{{ consul_domain }}"
        port_service: 8015
        port_admin: 18015
        baseuri: "batchreport"
        https_enabled: false
        secret_platform: "false"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    ingestexternal:
        vitam_component: ingest-external
        # DNS record for the service:
        # Modify if ihm-demo is not using consul (typical production deployment)
        host: "ingest-external.service.{{ consul_domain }}"
        port_admin: 28001
        port_service: 8443
        baseuri: "ingest-external"
        https_enabled: true
        secret_platform: "false"
        antivirus: "clamav"
        # uncomment if huge files need to be analyzed in more than 60s (default behavior)
        #scantimeout: 60000 # value in milliseconds
        # Directory where files should be placed for local ingest
        upload_dir: "/vitam/data/ingest-external/upload"
        # Directory where successful ingested files will be moved to
        success_dir: "/vitam/data/ingest-external/upload/success"
        # Directory where failed ingested files will be moved to
        fail_dir: "/vitam/data/ingest-external/upload/failure"
        # Action done to file after local ingest (see below for further information)
        upload_final_action: "MOVE"
        # log_level: "DEBUG"
        # upload_final_action can be set to three different values (lower or upper case does not matter)
        #   MOVE : After upload, the local file will be moved to either success_dir or fail_dir depending on the status of the ingest towards ingest-internal
        #   DELETE : After upload, the local file will be deleted if the upload succeeded
        #   NONE : After upload, nothing will be done to the local file (default option set if the value entered for upload_final_action does not exist)
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    ingestinternal:
        vitam_component: ingest-internal
        host: "ingest-internal.service.{{ consul_domain }}"
        port_service: 8100
        port_admin: 28100
        baseuri: "ingest"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    ihm_demo:
        vitam_component: ihm-demo
        host: "ihm-demo.service.{{ consul_domain }}"
        port_service: 8002
        port_admin: 28002
        baseurl: "/ihm-demo"
        static_content: "{{ vitam_defaults.folder.root_path }}/app/ihm-demo/v2"
        baseuri: "ihm-demo"
        https_enabled: false
        secret_platform: "false"
        # User session timeout in milliseconds (for shiro)
        session_timeout: 1800000
        secure_cookie: false
        # Specify here the realms you want to use for authentication in ihm-demo
        # You can set multiple realms, one per line
        # With multiple realms, the user will be able to choose between the allowed realms
        # Example: authentication_realms:
        #               - x509Realm
        #               - ldapRealm
        # Authorized values:
        # x509Realm: certificate
        # iniRealm: ini file
        # ldapRealm: ldap
        authentication_realms:
            # - x509Realm
            - iniRealm
            # - ldapRealm
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    logbook:
        vitam_component: logbook
        host: "logbook.service.{{ consul_domain }}"
        port_service: 9002
        port_admin: 29002
        baseuri: "logbook"
        https_enabled: false
        secret_platform: "true"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # Temporization delay (in seconds) for recent logbook operation events.
        # Set it to a reasonable delay to cover max clock difference across servers + VM/GC pauses
        operationTraceabilityTemporizationDelay: 300
        # Temporization delay (in seconds) for recent logbook lifecycle events.
        # Set it to a reasonable delay to cover max clock difference across servers + VM/GC pauses
        lifecycleTraceabilityTemporizationDelay: 300
        # Max entries selected per (Unit or Object Group) LFC traceability operation
        lifecycleTraceabilityMaxEntries: 100000
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    metadata:
        vitam_component: metadata
        host: "metadata.service.{{ consul_domain }}"
        port_service: 8200
        port_admin: 28200
        baseuri: "metadata"
        https_enabled: false
        secret_platform: "true"
        cluster_name: "{{ elasticsearch.data.cluster_name }}"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds

        # Archive Unit Profile cache settings (max entries in cache & retention timeout in seconds)
        archiveUnitProfileCacheMaxEntries: 100
        archiveUnitProfileCacheTimeoutInSeconds: 300

        # Schema validator cache settings (max entries in cache & retention timeout in seconds)
        schemaValidatorCacheMaxEntries: 100
        schemaValidatorCacheTimeoutInSeconds: 300

        acceptableRequestTime: 10 # value in seconds
    processing:
        vitam_component: processing
        host: "processing.service.{{ consul_domain }}"
        port_service: 8203
        port_admin: 28203
        baseuri: "processing"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        maxDistributionInMemoryBufferSize: 100000
        maxDistributionOnDiskBufferSize: 100000000
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    security_internal:
        vitam_component: security-internal
        host: "security-internal.service.{{ consul_domain }}"
        port_service: 8005
        port_admin: 28005
        baseuri: "security-internal"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds
    storageengine:
        vitam_component: storage
        host: "storage.service.{{ consul_domain }}"
        port_service: 9102
        port_admin: 29102
        baseuri: "storage"
        https_enabled: false
        secret_platform: "true"
        storageTraceabilityOverlapDelay: 300
        restoreBulkSize: 1000
        # batch thread pool size
        minBatchThreadPoolSize: 4
        maxBatchThreadPoolSize: 16
        # Digest computation timeout in seconds
        batchDigestComputationTimeout: 300
        # Offer synchronization batch size & thread pool size
        offerSynchronizationBulkSize: 1000
        offerSyncThreadPoolSize: 32
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 60 # value in seconds
    storageofferdefault:
        vitam_component: "offer"
        port_service: 9900
        port_admin: 29900
        baseuri: "offer"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 60 # value in seconds
    worker:
        vitam_component: worker
        host: "worker.service.{{ consul_domain }}"
        port_service: 9104
        port_admin: 29104
        baseuri: "worker"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 60 # value in seconds

        # Archive Unit Profile cache settings (max entries in cache & retention timeout in seconds)
        archiveUnitProfileCacheMaxEntries: 100
        archiveUnitProfileCacheTimeoutInSeconds: 300

        # Schema validator cache settings (max entries in cache & retention timeout in seconds)
        schemaValidatorCacheMaxEntries: 100
        schemaValidatorCacheTimeoutInSeconds: 300

    workspace:
        vitam_component: workspace
        host: "workspace.service.{{ consul_domain }}"
        port_service: 8201
        port_admin: 28201
        baseuri: "workspace"
        https_enabled: false
        secret_platform: "true"
        # log_level: "DEBUG"
        metrics_enabled: true
        logback_rolling_policy: true
        logback_max_file_size: "10MB"
        logback_total_size_cap: "5GB"
        jvm_log: false
        performance_logger: "false"
        consul_check_business: 10 # value in seconds
        consul_admin_check: 10 # value in seconds
        acceptableRequestTime: 10 # value in seconds

# If you want to deploy vitam in a single VM, add the vm name in this array
single_vm_hostnames: ['localhost']
