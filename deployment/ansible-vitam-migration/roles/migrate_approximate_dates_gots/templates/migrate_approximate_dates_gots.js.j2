var batch_size = 10;
var query = { "$and": [{ "_acd": { "$exists": false } }, { "_aud": { "$exists": false } }]};
var documents = db.getSiblingDB("metadata").ObjectGroup.find(query, { "_id": true }).toArray();
var total = documents.length;

for ( var counter = 0 ; counter <= total ; (counter+batch_size>total) ? counter += total%batch_size : counter += batch_size) {
  var bulkUpdateOps = [];
  var objects = documents.slice(counter, counter + batch_size).map(e => e._id);
  db.getSiblingDB("logbook").LogbookLifeCycleObjectGroup.find({ "_id": { "$in": objects } }, { "_id": true, "evDateTime": true, "events": { "$slice": -1 } }).forEach((e) => {
      bulkUpdateOps.push({
        updateOne: {
          filter: { "_id": e._id },
          update: {
            $set: { "_acd": e.evDateTime, "_aud": e.events[0].evDateTime },
          },
        },
      });
    });
  db.getSiblingDB("metadata").ObjectGroup.bulkWrite(bulkUpdateOps, { "ordered": false });
  print("number of items processed: " + counter + "/" + total); // output is not visible when running through ansible
}
